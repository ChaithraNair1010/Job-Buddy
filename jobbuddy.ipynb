{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4aeee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-01 03:38:46,952] INFO googleapiclient.discovery_cache - file_cache is only supported with oauth2client<4.0.0\n",
      "[2025-12-01 03:38:46,962] INFO googleapiclient.discovery_cache - file_cache is only supported with oauth2client<4.0.0\n",
      "[2025-12-01 03:38:46,966] WARNING google_adk.google.adk.runners - App name mismatch detected. The runner is configured with app name \"jobbuddy\", but the root agent was loaded from \"C:\\Users\\chait\\OneDrive\\Desktop\\job-buddy\\.venv\\Lib\\site-packages\\google\\adk\\agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gmail + Sheets clients ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-12-01 03:38:47,545] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:38:48,832] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:38:48,842] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "[2025-12-01 03:38:48,842] WARNING google_genai.types - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "[2025-12-01 03:38:48,849] INFO jobbuddy - [Tool] fetch_recent_job_emails called with max_results=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG query in tool: (from:jobs-noreply@linkedin.com OR subject:\"Your application\" OR subject:\"Application received\" OR subject:\"Thank you for applying\" OR subject:\"was sent\" OR subject:\"status\" OR subject:\"update\" OR subject:\"applied to\")\n",
      "DEBUG resultSizeEstimate: 201 len(messages): 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chait\\AppData\\Local\\Temp\\ipykernel_14348\\1598437832.py:173: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  received_at = datetime.datetime.utcfromtimestamp(internal_ts).isoformat() + \"Z\"\n",
      "[2025-12-01 03:38:52,317] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:39:04,195] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:39:04,204] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "[2025-12-01 03:39:04,204] INFO jobbuddy - [Tool] save_parsed_applications called\n",
      "[2025-12-01 03:39:04,780] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:39:06,586] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:39:06,594] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "[2025-12-01 03:39:07,132] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:39:08,807] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:39:08,807] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "[2025-12-01 03:39:08,812] INFO jobbuddy - [Tool] load_tracker_snapshot called\n",
      "[2025-12-01 03:39:10,032] INFO jobbuddy - [Tool] Loaded 14 tracker rows from sheet.\n",
      "[2025-12-01 03:39:10,538] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:39:11,872] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:39:11,882] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "[2025-12-01 03:39:11,884] INFO jobbuddy - [Tool] sync_tracker_sheet called\n",
      "[2025-12-01 03:39:11,886] INFO jobbuddy - [Tool] sync_tracker_sheet done: new_rows=0, updated_rows=0, total=14\n",
      "[2025-12-01 03:39:12,384] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:39:19,967] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:39:19,972] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "[2025-12-01 03:39:20,512] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:39:21,504] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:39:21,509] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "[2025-12-01 03:39:21,512] INFO jobbuddy - [Tool] compute_insights called\n",
      "[2025-12-01 03:39:22,075] INFO google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "[2025-12-01 03:39:26,039] INFO httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "[2025-12-01 03:39:26,042] INFO google_adk.google.adk.models.google_llm - Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of your job search activity this week:\n",
      "\n",
      "You applied to **14 roles** this week.\n",
      "**1 application moved to an interview** stage.\n",
      "**1 application was rejected**.\n",
      "\n",
      "Here are some applications that look stalled and could use a follow-up:\n",
      "\n",
      "*   **Reyes Beverage Group Corporate** (IT Applications Security Data Analyst): Send a polite follow-up email to the recruiter.\n",
      "*   **Internet Brands** (Associate Data Analyst): Send a polite follow-up email to the recruiter.\n",
      "*   **Snyk** (Strategic Analytics Associate): Send a polite follow-up email to the recruiter.\n",
      "*   **Qemailserver** (Unknown role): Send a polite follow-up email to the recruiter.\n",
      "*   **Danson Solutions** (Unknown): Send a thank-you / check in on next steps.\n",
      "*   **Sony** (Associate Data Scientist): Send a polite follow-up email to the recruiter.\n",
      "*   **Bimbo Bakeries USA** (Analytics Analyst): Send a polite follow-up email to the recruiter.\n",
      "*   **Plymouth Rock Assurance** (Unknown): Send a polite follow-up email to the recruiter.\n",
      "*   **BDO** (Advisory Associate, Valuation & Capital Market Analysis, Fixed Assets): Send a polite follow-up email to the recruiter.\n",
      "*   **Fanatee** (Data Analyst): Send a polite follow-up email to the recruiter.\n",
      "*   **CorVel** (Data Analyst I): Send a polite follow-up email to the recruiter.\n",
      "*   **Alexander Chapman** (Unknown): Send a polite follow-up email to the recruiter.\n",
      "*   **SAIVA AI** (Unknown): Send a polite follow-up email to the recruiter.\n",
      "\n",
      "Keep up the great work!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import FunctionTool\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.genai import types\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "\n",
    "# Your Gemini API key here (you can also move this to .env)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"Enter your google api key\"\n",
    "\n",
    "APP_NAME = \"jobbuddy\"\n",
    "USER_ID = \"demo_user\"\n",
    "SESSION_ID = \"demo_session\"\n",
    "\n",
    "MODEL_ID = \"gemini-2.5-flash\"\n",
    "\n",
    "# Gmail (read-only) + Sheets (read/write)\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/gmail.readonly\",\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "]\n",
    "\n",
    "# Your Sheet config\n",
    "JOBBUDDY_SHEET_ID = \"Enter your sheet id\"\n",
    "JOBBUDDY_SHEET_NAME = \"Applications\"  # must match tab name\n",
    "\n",
    "TRACKER_COLUMNS = [\n",
    "    \"application_id\",\n",
    "    \"company\",\n",
    "    \"role\",\n",
    "    \"source\",\n",
    "    \"status\",\n",
    "    \"applied_date\",\n",
    "    \"last_activity_date\",\n",
    "    \"next_action\",\n",
    "    \"priority\",\n",
    "    \"thread_id\",\n",
    "]\n",
    "\n",
    "# Optional retry config for Gemini\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,\n",
    "    exp_base=7,\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(levelname)s %(name)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"jobbuddy\")\n",
    "\n",
    "\n",
    "# ===================== OAuth helper =====================\n",
    "\n",
    "def get_creds() -> Credentials:\n",
    "    \"\"\"\n",
    "    OAuth helper for local VS Code / desktop using a Desktop OAuth client.\n",
    "\n",
    "    Flow:\n",
    "    1. If token.json exists & is valid -> reuse it.\n",
    "    2. Else:\n",
    "       - Use InstalledAppFlow.from_client_secrets_file(\"credentials.json\", SCOPES)\n",
    "       - Run a local server for the OAuth callback.\n",
    "    \"\"\"\n",
    "    creds: Credentials | None = None\n",
    "\n",
    "    # Reuse token if we have one\n",
    "    if os.path.exists(\"token.json\"):\n",
    "        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "\n",
    "    # If no valid creds, start the flow\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            if not os.path.exists(\"credentials.json\"):\n",
    "                raise FileNotFoundError(\n",
    "                    \"credentials.json not found. Place your Desktop OAuth client JSON \"\n",
    "                    \"in the project root (same folder where you run this script).\"\n",
    "                )\n",
    "\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                \"credentials.json\",\n",
    "                scopes=SCOPES,\n",
    "            )\n",
    "\n",
    "            creds = flow.run_local_server(\n",
    "                port=0,\n",
    "                open_browser=True,\n",
    "                prompt=\"consent\",\n",
    "            )\n",
    "\n",
    "        # Save token for future runs\n",
    "        with open(\"token.json\", \"w\") as token_file:\n",
    "            token_file.write(creds.to_json())\n",
    "\n",
    "    return creds\n",
    "\n",
    "\n",
    "creds = get_creds()  # <-- will open browser on first run\n",
    "\n",
    "gmail_service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "sheets_service = build(\"sheets\", \"v4\", credentials=creds)\n",
    "\n",
    "print(\"✅ Gmail + Sheets clients ready\")\n",
    "\n",
    "\n",
    "# ===================== TOOL 1: Gmail fetch =====================\n",
    "\n",
    "def fetch_recent_job_emails(max_results: int, tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Use Gmail API to fetch recent job application–style emails.\n",
    "\n",
    "    Writes:\n",
    "      tool_context.state[\"raw_job_emails\"] = [ {thread_id, subject, from, snippet, received_at, ...}, ... ]\n",
    "    Returns the same list in the tool result so the agent can see it.\n",
    "    \"\"\"\n",
    "    logger.info(f\"[Tool] fetch_recent_job_emails called with max_results={max_results}\")\n",
    "\n",
    "    # Focus on actual applications / confirmations, not alerts / newsletters\n",
    "    query = (\n",
    "        '(from:jobs-noreply@linkedin.com '\n",
    "        'OR subject:\"Your application\" '\n",
    "        'OR subject:\"Application received\" '\n",
    "        'OR subject:\"Thank you for applying\" '\n",
    "        'OR subject:\"was sent\" '\n",
    "        'OR subject:\"status\" '\n",
    "        'OR subject:\"update\" '\n",
    "        'OR subject:\"applied to\")'\n",
    "    )\n",
    "    print(\"DEBUG query in tool:\", query)\n",
    "\n",
    "    response = gmail_service.users().messages().list(\n",
    "        userId=\"me\",\n",
    "        q=query,\n",
    "        maxResults=max_results,\n",
    "    ).execute()\n",
    "\n",
    "    size = response.get(\"resultSizeEstimate\")\n",
    "    message_refs = response.get(\"messages\", [])\n",
    "    print(\"DEBUG resultSizeEstimate:\", size, \"len(messages):\", len(message_refs))\n",
    "\n",
    "    emails: List[Dict[str, Any]] = []\n",
    "\n",
    "    for ref in message_refs or []:\n",
    "        msg = gmail_service.users().messages().get(\n",
    "            userId=\"me\",\n",
    "            id=ref[\"id\"],\n",
    "            format=\"metadata\",\n",
    "            metadataHeaders=[\"From\", \"Subject\", \"Date\", \"List-Id\", \"X-Source\"],\n",
    "        ).execute()\n",
    "\n",
    "        headers = {\n",
    "            h[\"name\"].lower(): h[\"value\"]\n",
    "            for h in msg.get(\"payload\", {}).get(\"headers\", [])\n",
    "        }\n",
    "        snippet = msg.get(\"snippet\", \"\")\n",
    "        internal_ts = int(msg.get(\"internalDate\", 0)) / 1000.0\n",
    "        received_at = datetime.datetime.utcfromtimestamp(internal_ts).isoformat() + \"Z\"\n",
    "\n",
    "        emails.append(\n",
    "            {\n",
    "                \"thread_id\": msg.get(\"threadId\"),\n",
    "                \"message_id\": msg.get(\"id\"),\n",
    "                \"from\": headers.get(\"from\", \"\"),\n",
    "                \"subject\": headers.get(\"subject\", \"\"),\n",
    "                \"snippet\": snippet,\n",
    "                \"received_at\": received_at,\n",
    "                \"raw_headers\": {\n",
    "                    \"date\": headers.get(\"date\"),\n",
    "                    \"list-id\": headers.get(\"list-id\"),\n",
    "                    \"x-source\": headers.get(\"x-source\"),\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    tool_context.state[\"raw_job_emails\"] = emails\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"count\": len(emails),\n",
    "        \"emails\": emails,\n",
    "    }\n",
    "\n",
    "\n",
    "fetch_emails_tool = FunctionTool(func=fetch_recent_job_emails)\n",
    "\n",
    "\n",
    "# ===================== TOOL 2: Save parsed applications (LLM → state) =====================\n",
    "\n",
    "def save_parsed_applications(\n",
    "    parsed_applications: List[Dict[str, Any]],\n",
    "    tool_context: ToolContext,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save the LLM-parsed applications into tool_context.state['parsed_applications'].\n",
    "\n",
    "    The agent should pass a list like:\n",
    "    [\n",
    "      {\n",
    "        \"thread_id\": \"...\",\n",
    "        \"company\": \"...\",\n",
    "        \"role\": \"...\",\n",
    "        \"source\": \"LinkedIn\" | \"Company ATS\" | \"Company Site\" | \"Unknown\",\n",
    "        \"status\": \"Applied\" | \"Screening\" | \"Interview\" | \"Rejected\" | \"Offer\",\n",
    "        \"applied_date\": \"YYYY-MM-DD\",\n",
    "        \"last_email_date\": \"YYYY-MM-DDTHH:MM:SSZ\",\n",
    "        \"interview_date\": \"YYYY-MM-DD\" | null\n",
    "      },\n",
    "      ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    logger.info(\"[Tool] save_parsed_applications called\")\n",
    "    tool_context.state[\"parsed_applications\"] = parsed_applications or []\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"count\": len(parsed_applications or []),\n",
    "    }\n",
    "\n",
    "\n",
    "save_parsed_apps_tool = FunctionTool(func=save_parsed_applications)\n",
    "\n",
    "\n",
    "# ===================== TOOL 3: Load tracker snapshot from Sheet =====================\n",
    "\n",
    "def load_tracker_snapshot(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Read JobBuddy tracker rows from the Google Sheet into state[\"tracker_rows\"].\n",
    "    \"\"\"\n",
    "    logger.info(\"[Tool] load_tracker_snapshot called\")\n",
    "\n",
    "    if JOBBUDDY_SHEET_ID == \"JOBBUDDY_SHEET_ID\":\n",
    "        raise ValueError(\"Set JOBBUDDY_SHEET_ID to your real Sheet ID.\")\n",
    "\n",
    "    range_ = f\"{JOBBUDDY_SHEET_NAME}!A:Z\"\n",
    "    result = sheets_service.spreadsheets().values().get(\n",
    "        spreadsheetId=JOBBUDDY_SHEET_ID,\n",
    "        range=range_,\n",
    "    ).execute()\n",
    "\n",
    "    values = result.get(\"values\", [])\n",
    "    if not values:\n",
    "        tool_context.state[\"tracker_rows\"] = []\n",
    "        return {\"status\": \"success\", \"row_count\": 0}\n",
    "\n",
    "    header = values[0]\n",
    "    data_rows = values[1:]\n",
    "\n",
    "    if header[: len(TRACKER_COLUMNS)] != TRACKER_COLUMNS:\n",
    "        raise ValueError(\n",
    "            f\"Sheet header mismatch.\\nExpected: {TRACKER_COLUMNS}\\nGot: {header}\"\n",
    "        )\n",
    "\n",
    "    tracker_rows: List[Dict[str, Any]] = []\n",
    "    for i, row in enumerate(data_rows, start=2):  # Sheet row index\n",
    "        row_padded = row + [\"\"] * (len(TRACKER_COLUMNS) - len(row))\n",
    "        row_dict = {\n",
    "            col: row_padded[idx]\n",
    "            for idx, col in enumerate(TRACKER_COLUMNS)\n",
    "        }\n",
    "        row_dict[\"sheet_row\"] = i\n",
    "        tracker_rows.append(row_dict)\n",
    "\n",
    "    tool_context.state[\"tracker_rows\"] = tracker_rows\n",
    "\n",
    "    logger.info(f\"[Tool] Loaded {len(tracker_rows)} tracker rows from sheet.\")\n",
    "    return {\"status\": \"success\", \"row_count\": len(tracker_rows)}\n",
    "\n",
    "\n",
    "load_tracker_tool = FunctionTool(func=load_tracker_snapshot)\n",
    "\n",
    "\n",
    "# ===================== TOOL 4: Sync tracker to Sheet =====================\n",
    "\n",
    "def _row_dict_to_sheet_values(row: Dict[str, Any]) -> List[Any]:\n",
    "    return [row.get(col, \"\") for col in TRACKER_COLUMNS]\n",
    "\n",
    "\n",
    "def sync_tracker_sheet(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Idempotently upsert parsed applications into tracker_rows and sync to the sheet.\n",
    "    \"\"\"\n",
    "    logger.info(\"[Tool] sync_tracker_sheet called\")\n",
    "\n",
    "    state = tool_context.state\n",
    "    parsed_apps: List[Dict[str, Any]] = state.get(\"parsed_applications\", [])\n",
    "    tracker_rows: List[Dict[str, Any]] = state.get(\"tracker_rows\", [])\n",
    "\n",
    "    index_by_thread = {\n",
    "        row[\"thread_id\"]: row for row in tracker_rows if row.get(\"thread_id\")\n",
    "    }\n",
    "\n",
    "    new_rows_to_append: List[Dict[str, Any]] = []\n",
    "    changed_existing_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    new_rows = 0\n",
    "    updated_rows = 0\n",
    "\n",
    "    for app in parsed_apps:\n",
    "        thread_id = app.get(\"thread_id\")\n",
    "        if not thread_id:\n",
    "            continue\n",
    "\n",
    "        existing = index_by_thread.get(thread_id)\n",
    "\n",
    "        if existing is None:\n",
    "            new_row = {\n",
    "                \"application_id\": app.get(\"application_id\") or f\"app_{len(tracker_rows) + len(new_rows_to_append) + 1}\",\n",
    "                \"company\": app.get(\"company\"),\n",
    "                \"role\": app.get(\"role\"),\n",
    "                \"source\": app.get(\"source\"),\n",
    "                \"status\": app.get(\"status\"),\n",
    "                \"applied_date\": app.get(\"applied_date\"),\n",
    "                \"last_activity_date\": (\n",
    "                    app.get(\"last_email_date\", \"\")[:10] if app.get(\"last_email_date\") else \"\"\n",
    "                ),\n",
    "                \"next_action\": \"\",\n",
    "                \"priority\": \"\",\n",
    "                \"thread_id\": thread_id,\n",
    "                \"sheet_row\": None,\n",
    "            }\n",
    "            new_rows_to_append.append(new_row)\n",
    "            index_by_thread[thread_id] = new_row\n",
    "            new_rows += 1\n",
    "\n",
    "        else:\n",
    "            changed = False\n",
    "\n",
    "            # Refresh all logical fields when we re-parse the same thread\n",
    "            for key in [\"company\", \"role\", \"source\", \"status\", \"applied_date\"]:\n",
    "                if app.get(key) and existing.get(key) != app.get(key):\n",
    "                    existing[key] = app[key]\n",
    "                    changed = True\n",
    "\n",
    "            # last_activity_date from latest email\n",
    "            if app.get(\"last_email_date\"):\n",
    "                led = app[\"last_email_date\"][:10]\n",
    "                if existing.get(\"last_activity_date\") != led:\n",
    "                    existing[\"last_activity_date\"] = led\n",
    "                    changed = True\n",
    "\n",
    "            if changed:\n",
    "                changed_existing_rows.append(existing)\n",
    "                updated_rows += 1\n",
    "\n",
    "    # Update in-memory tracker\n",
    "    tracker_rows.extend(new_rows_to_append)\n",
    "    state[\"tracker_rows\"] = tracker_rows\n",
    "\n",
    "    # Append new rows to Sheet\n",
    "    if new_rows_to_append:\n",
    "        values_to_append = [_row_dict_to_sheet_values(r) for r in new_rows_to_append]\n",
    "        body = {\"values\": values_to_append}\n",
    "        sheets_service.spreadsheets().values().append(\n",
    "            spreadsheetId=JOBBUDDY_SHEET_ID,\n",
    "            range=f\"{JOBBUDDY_SHEET_NAME}!A2\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            insertDataOption=\"INSERT_ROWS\",\n",
    "            body=body,\n",
    "        ).execute()\n",
    "        logger.info(f\"[Tool] Appended {len(values_to_append)} new rows to sheet.\")\n",
    "\n",
    "    # Batch update existing rows\n",
    "    if changed_existing_rows:\n",
    "        data = []\n",
    "        for row in changed_existing_rows:\n",
    "            sr = row.get(\"sheet_row\")\n",
    "            if not sr:\n",
    "                continue\n",
    "            data.append(\n",
    "                {\n",
    "                    \"range\": f\"{JOBBUDDY_SHEET_NAME}!A{sr}:J{sr}\",\n",
    "                    \"values\": [_row_dict_to_sheet_values(row)],\n",
    "                }\n",
    "            )\n",
    "        if data:\n",
    "            body = {\n",
    "                \"valueInputOption\": \"USER_ENTERED\",\n",
    "                \"data\": data,\n",
    "            }\n",
    "            sheets_service.spreadsheets().values().batchUpdate(\n",
    "                spreadsheetId=JOBBUDDY_SHEET_ID,\n",
    "                body=body,\n",
    "            ).execute()\n",
    "            logger.info(f\"[Tool] Updated {len(data)} existing rows in sheet.\")\n",
    "\n",
    "    total_rows = len(tracker_rows)\n",
    "    logger.info(\n",
    "        f\"[Tool] sync_tracker_sheet done: new_rows={new_rows}, updated_rows={updated_rows}, total={total_rows}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"new_rows\": new_rows,\n",
    "        \"updated_rows\": updated_rows,\n",
    "        \"total_rows\": total_rows,\n",
    "    }\n",
    "\n",
    "\n",
    "sync_tracker_tool = FunctionTool(func=sync_tracker_sheet)\n",
    "\n",
    "\n",
    "# ===================== TOOL 5: Compute insights =====================\n",
    "\n",
    "def compute_insights(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compute weekly stats + stalled applications from tracker_rows.\n",
    "    \"\"\"\n",
    "    logger.info(\"[Tool] compute_insights called\")\n",
    "\n",
    "    state = tool_context.state\n",
    "    tracker_rows: List[Dict[str, Any]] = state.get(\"tracker_rows\", [])\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    seven_days_ago = today - datetime.timedelta(days=7)\n",
    "    three_days_ago = today - datetime.timedelta(days=3)\n",
    "\n",
    "    applied_this_week = 0\n",
    "    moved_to_interview = 0\n",
    "    rejected_this_week = 0\n",
    "    stalled: List[Dict[str, Any]] = []\n",
    "\n",
    "    for row in tracker_rows:\n",
    "        applied_str = row.get(\"applied_date\")\n",
    "        last_str = row.get(\"last_activity_date\")\n",
    "        status = (row.get(\"status\") or \"\").lower()\n",
    "\n",
    "        applied_date = datetime.date.fromisoformat(applied_str) if applied_str else None\n",
    "        last_activity = datetime.date.fromisoformat(last_str) if last_str else None\n",
    "\n",
    "        if applied_date and applied_date >= seven_days_ago:\n",
    "            applied_this_week += 1\n",
    "        if status == \"interview\" and last_activity and last_activity >= seven_days_ago:\n",
    "            moved_to_interview += 1\n",
    "        if status == \"rejected\" and last_activity and last_activity >= seven_days_ago:\n",
    "            rejected_this_week += 1\n",
    "\n",
    "        if status in {\"applied\", \"screening\", \"interview\"} and last_activity:\n",
    "            if last_activity <= three_days_ago:\n",
    "                stalled.append(\n",
    "                    {\n",
    "                        \"company\": row.get(\"company\"),\n",
    "                        \"role\": row.get(\"role\"),\n",
    "                        \"status\": row.get(\"status\"),\n",
    "                        \"last_activity_date\": row.get(\"last_activity_date\"),\n",
    "                        \"thread_id\": row.get(\"thread_id\"),\n",
    "                        \"suggested_next_action\": (\n",
    "                            \"Send a polite follow-up email to the recruiter.\"\n",
    "                            if status in {\"applied\", \"screening\"}\n",
    "                            else \"Send a thank-you / check in on next steps.\"\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    stats = {\n",
    "        \"applied_this_week\": applied_this_week,\n",
    "        \"moved_to_interview\": moved_to_interview,\n",
    "        \"rejected_this_week\": rejected_this_week,\n",
    "        \"total_tracked\": len(tracker_rows),\n",
    "    }\n",
    "\n",
    "    summary_lines = [\n",
    "        f\"You have {stats['total_tracked']} total applications.\",\n",
    "        f\"This week: {applied_this_week} applied, {moved_to_interview} moved to interviews, \"\n",
    "        f\"{rejected_this_week} rejected.\",\n",
    "        f\"{len(stalled)} applications look stalled (no activity for 3+ days).\",\n",
    "    ]\n",
    "    summary = \" \".join(summary_lines)\n",
    "\n",
    "    insights = {\n",
    "        \"summary\": summary,\n",
    "        \"stats\": stats,\n",
    "        \"stalled\": stalled,\n",
    "        \"generated_at\": today.isoformat(),\n",
    "    }\n",
    "\n",
    "    state[\"weekly_insights\"] = insights\n",
    "\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        **insights,\n",
    "    }\n",
    "\n",
    "\n",
    "compute_insights_tool = FunctionTool(func=compute_insights)\n",
    "\n",
    "\n",
    "# ===================== InboxAgent (LLM does parsing) =====================\n",
    "\n",
    "inbox_agent = Agent(\n",
    "    model=MODEL_ID,\n",
    "    name=\"InboxAgent\",\n",
    "    description=\"Parses Gmail job-related emails into normalized job applications.\",\n",
    "    instruction=\"\"\"\n",
    "You are the InboxAgent for JobBuddy.\n",
    "\n",
    "Your job is to:\n",
    "1. Call the tool `fetch_recent_job_emails(max_results)` to get recent job-related emails.\n",
    "   - The tool returns a JSON object with a list `emails`.\n",
    "   - Each email has at least: thread_id, from, subject, snippet, received_at, raw_headers.\n",
    "\n",
    "2. From this tool output, decide for each email whether it is:\n",
    "   - a new job application,\n",
    "   - an update to an existing application (same thread_id),\n",
    "   - or not job-related (ignore it).\n",
    "\n",
    "3. Build a list `parsed_applications`, where each item is a JSON object:\n",
    "   {\n",
    "     \"thread_id\": str,\n",
    "     \"company\": str,\n",
    "     \"role\": str,\n",
    "     \"source\": str | null,     // e.g. \"LinkedIn\", \"Indeed\", \"Glassdoor\", \"Company ATS\", \"Company Site\", \"Unknown\"\n",
    "     \"status\": str,            // one of: \"Applied\", \"Screening\", \"Interview\", \"Rejected\", \"Offer\"\n",
    "     \"applied_date\": str,      // YYYY-MM-DD (if unknown, infer a reasonable date from received_at)\n",
    "     \"last_email_date\": str,   // ISO timestamp from the email's received_at\n",
    "     \"interview_date\": str | null\n",
    "   }\n",
    "\n",
    "4. Then call the tool `save_parsed_applications(parsed_applications=...)`\n",
    "   so that these results are written into session.state['parsed_applications'].\n",
    "\n",
    "Rules:\n",
    "- Be conservative: only mark an email as a job application if the subject/snippet clearly indicates\n",
    "  an application confirmation, application received, or similar.\n",
    "- Try your best to extract clear company and role names from the subject and snippet.\n",
    "- Use the email \"from\" domain to guess the source when possible (e.g., linkedin.com -> \"LinkedIn\").\n",
    "- If unsure about any field, set it to null (or a sensible default like \"Unknown\").\n",
    "- Do NOT invent applications that aren't actually in the tool output.\n",
    "- After using the tools, in your final answer, briefly summarize how many applications you found\n",
    "  and their statuses.\n",
    "\"\"\",\n",
    "    tools=[fetch_emails_tool, save_parsed_apps_tool],\n",
    "    output_key=\"inbox_summary\",\n",
    ")\n",
    "\n",
    "\n",
    "# ===================== TrackerAgent =====================\n",
    "\n",
    "tracker_agent = Agent(\n",
    "    model=MODEL_ID,\n",
    "    name=\"TrackerAgent\",\n",
    "    description=\"Keeps the JobBuddy Google Sheet tracker in sync with applications.\",\n",
    "    instruction=\"\"\"\n",
    "You are the TrackerAgent for JobBuddy.\n",
    "\n",
    "1. Call `load_tracker_snapshot()` to load tracker rows into session.state['tracker_rows'].\n",
    "2. Read `parsed_applications` from session.state (these were stored by InboxAgent via the tool).\n",
    "3. Plan how to apply these to the tracker:\n",
    "   - If thread_id already exists -> update that row.\n",
    "   - Otherwise -> create a new row.\n",
    "4. Call `sync_tracker_sheet()` to perform the idempotent upsert.\n",
    "\n",
    "Do NOT manually mutate tracker_rows in your textual response; let the tool update the state.\n",
    "In your final answer, report how many rows were created, updated, and the total rows.\n",
    "\"\"\",\n",
    "    tools=[load_tracker_tool, sync_tracker_tool],\n",
    "    output_key=\"tracker_summary\",\n",
    ")\n",
    "\n",
    "\n",
    "# ===================== InsightsAgent =====================\n",
    "\n",
    "insights_agent = Agent(\n",
    "    model=MODEL_ID,\n",
    "    name=\"InsightsAgent\",\n",
    "    description=\"Summarizes weekly job search progress and reminders.\",\n",
    "    instruction=\"\"\"\n",
    "You are the InsightsAgent for JobBuddy.\n",
    "\n",
    "1. Assume the tracker has already been synced and session.state['tracker_rows']\n",
    "   is up to date.\n",
    "2. Call `compute_insights()` to compute weekly stats and stalled applications.\n",
    "3. Then, produce a concise, friendly weekly summary including:\n",
    "   - How many roles were applied to this week.\n",
    "   - How many moved to interviews.\n",
    "   - How many were rejected.\n",
    "   - A bulleted or clearly separated list of stalled applications and suggested follow-ups.\n",
    "\n",
    "Tone: practical, encouraging, and specific.\n",
    "\"\"\",\n",
    "    tools=[compute_insights_tool],\n",
    "    output_key=\"insights_summary\",\n",
    ")\n",
    "\n",
    "\n",
    "# ===================== Multi-agent pipeline =====================\n",
    "\n",
    "jobbuddy_pipeline = SequentialAgent(\n",
    "    name=\"JobBuddyPipeline\",\n",
    "    sub_agents=[inbox_agent, tracker_agent, insights_agent],\n",
    ")\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "\n",
    "session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "runner = Runner(\n",
    "    agent=jobbuddy_pipeline,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    ")\n",
    "\n",
    "from google.genai import types as genai_types\n",
    "\n",
    "def run_jobbuddy_once(user_message: str) -> str:\n",
    "    \"\"\"\n",
    "    Run the JobBuddy pipeline once and return the final text from InsightsAgent.\n",
    "    Assumes the session was already created with `await session_service.create_session(...)`.\n",
    "    \"\"\"\n",
    "    content = genai_types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[genai_types.Part(text=user_message)],\n",
    "    )\n",
    "\n",
    "    final_text = \"No response.\"\n",
    "\n",
    "    events = runner.run(\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        new_message=content,\n",
    "    )\n",
    "\n",
    "    for event in events:\n",
    "        if event.is_final_response() and event.content and event.content.parts:\n",
    "            final_text = event.content.parts[0].text\n",
    "\n",
    "    return final_text\n",
    "\n",
    "\n",
    "summary = run_jobbuddy_once(\n",
    "    \"Sync my job search from Gmail and tell me how my week went.\"\n",
    ")\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
